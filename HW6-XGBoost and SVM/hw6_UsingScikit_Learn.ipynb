{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "473a5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bde9559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\t# load data \n",
    "\tdata = pd.read_csv(\n",
    "\t\t'http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data', header=None)\n",
    "\tp_ = data.shape[1]\n",
    "\tp = p_ - 1\n",
    "\tX = data.iloc[:, :p]\n",
    "\ty = data.iloc[:, p]\n",
    "\treturn X.values, y.values\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19263ce",
   "metadata": {},
   "source": [
    "XGBoost Classifier with default setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a024b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='mlogloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "Training accuracy is 99.78 and testing accuracy is 95.87 %\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "print(xgb_clf)\n",
    "xgb_clf = xgb_clf.fit(X_train, y_train)\n",
    "training_score = xgb_clf.score(X_train, y_train) \n",
    "testing_score = xgb_clf.score(X_test, y_test)\n",
    "print(\"Training accuracy is %.2f and testing accuracy is %.2f\"%(training_score*100, testing_score*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3fcc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparams(model, param_grid):\n",
    "    \n",
    "    X, y = load_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "    \n",
    "    rs_clf = RandomizedSearchCV(model, \n",
    "    param_grid, \n",
    "    n_iter=20, \n",
    "    n_jobs = 10,\n",
    "    cv = 10,\n",
    "    scoring='accuracy',\n",
    "    refit = True, \n",
    "    random_state = 0, verbose = 0)\n",
    "\n",
    "    rs_clf.fit(X_train, y_train)\n",
    "\n",
    "    score = rs_clf.best_score_\n",
    "    param_recommend = rs_clf.best_params_\n",
    "    print(param_recommend)\n",
    "\n",
    "    print('Training Accuracy %.2f'%(rs_clf.score(X_train, y_train)*100),'%')\n",
    "    print('Testing Accuracy %.2f'%(rs_clf.score(X_test, y_test)*100),'%')\n",
    "\n",
    "    return rs_clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b70a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators':[10, 30, 50, 70, 90, 150, 200],\n",
    "    'max_depth':[100,200,300,400,500,600,700,800,1000,2000]\n",
    "}\n",
    "xgb_tuned = tune_hyperparams(xgb.XGBClassifier(use_label_encoder = False, eval_metric = 'mlogloss'), param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xgb_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2f087",
   "metadata": {},
   "source": [
    "Linear SVM with default setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de63db2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC()\n",
      "Training accuracy is 88.59 and testing accuracy is 86.43 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm = LinearSVC()\n",
    "print(svm)\n",
    "svm.fit(X_train, y_train)\n",
    "training_score_svm = svm.score(X_train, y_train) \n",
    "testing_score_svm = svm.score(X_test, y_test)\n",
    "# print(training_score_svm, testing_score_svm)\n",
    "print(\"Training accuracy is %.2f and testing accuracy is %.2f\"%(training_score_svm*100, testing_score_svm*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a59f1",
   "metadata": {},
   "source": [
    "Gaussian SVM with default setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa0de1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "Training accuracy is 71.36 and testing accuracy is 66.23 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm = SVC(kernel='rbf')\n",
    "print(svm)\n",
    "svm.fit(X_train, y_train)\n",
    "training_score_svm = svm.score(X_train, y_train) \n",
    "testing_score_svm = svm.score(X_test, y_test)\n",
    "# print(training_score_svm, testing_score_svm)\n",
    "print(\"Training accuracy is %.2f and testing accuracy is %.2f\"%(training_score_svm*100, testing_score_svm*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f677dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(estimator=LinearSVC(),\n",
      "             param_grid={'C': [0.1, 1, 10, 100],\n",
      "                         'max_iter': [10, 1000, 10000, 100000]})\n",
      "Best parameters are: LinearSVC(C=0.1, max_iter=100000)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1,1, 10, 100],\n",
    "    'max_iter':[10, 1000, 10000,100000 ]\n",
    "}\n",
    "svcGrid_linear = GridSearchCV(LinearSVC(), param_grid, refit=True, verbose=0)\n",
    "svcGrid_linear.fit(X_train,y_train)\n",
    "print(svcGrid_linear)\n",
    "print('Best parameters are:',svcGrid_linear.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "398ae4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(estimator=SVC(),\n",
      "             param_grid={'C': [0.1, 1, 10, 100],\n",
      "                         'max_iter': [10, 1000, 10000, 100000]})\n",
      "Best parameters are: SVC(C=100, max_iter=10000)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1,1, 10, 100],\n",
    "    'max_iter':[10, 1000, 10000,100000 ]\n",
    "}\n",
    "svcGrid_gaussian = GridSearchCV(SVC(kernel = 'rbf'), param_grid, refit=True, verbose=0)\n",
    "svcGrid_gaussian.fit(X_train,y_train)\n",
    "print(svcGrid_gaussian)\n",
    "print('Best parameters are:',svcGrid_gaussian.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21b7eb4",
   "metadata": {},
   "source": [
    "Linear SVM with hypertuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bd19767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 92.45 and testing accuracy is 91.75 %\n"
     ]
    }
   ],
   "source": [
    "svm_linear_tuned = LinearSVC(C=0.1, max_iter = 100000)\n",
    "svm_linear_tuned.fit(X_train, y_train)\n",
    "training_score_svm = svm_linear_tuned.score(X_train, y_train) \n",
    "testing_score_svm = svm_linear_tuned.score(X_test, y_test)\n",
    "# print(training_score_svm, testing_socre_svm)\n",
    "print(\"Training accuracy is %.2f and testing accuracy is %.2f\"%(training_score_svm*100, testing_score_svm*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891d98d5",
   "metadata": {},
   "source": [
    "Gaussian SVM with hypertuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b14c2aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 84.13 and testing accuracy is 83.06 %\n"
     ]
    }
   ],
   "source": [
    "svm_gaussian_tuned = SVC(kernel = 'rbf', C=100, max_iter = 10000)\n",
    "svm_gaussian_tuned.fit(X_train, y_train)\n",
    "training_score_svm = svm_gaussian_tuned.score(X_train, y_train) \n",
    "testing_score_svm = svm_gaussian_tuned.score(X_test, y_test)\n",
    "# print(training_score_svm, testing_socre_svm)\n",
    "print(\"Training accuracy is %.2f and testing accuracy is %.2f\"%(training_score_svm*100, testing_score_svm*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c59a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load data\n",
    "    X, y = load_data()\n",
    "\n",
    "    # TO DO:\n",
    "    # Randomly split the data in to training set and testing test; \n",
    "    # Let testing set contain 20% of total dataset\n",
    "    # You can check the train_test_split function in sklearn package\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "    # TO DO：\n",
    "    # 1. Using the XgboostClassifier (default setting), report the training and testing accuracy\n",
    "    xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "    xgb_clf = xgb_clf.fit(X_train, y_train)\n",
    "    training_score = xgb_clf.score(X_train, y_train) \n",
    "    testing_socre = xgb_clf.score(X_test, y_test)\n",
    "    print(training_score, testing_socre)\n",
    "    # 2. Tuning the n_estimator and max_depth, compare the results\n",
    "    xgb_tuned = xgb.XGBClassifier(n_estimators = 30, max_depth = 100, use_label_encoder=False, eval_metric='mlogloss')\n",
    "    xgb_tuned = xgb_tuned.fit(X_train, y_train)\n",
    "    training_score = xgb_tuned.score(X_train, y_train) \n",
    "    testing_socre = xgb_tuned.score(X_test, y_test)\n",
    "    print(training_score, testing_socre)\n",
    "    # TO DO：\n",
    "    # 1. Using Linear SVM (default setting), report the training and testing accuracy\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "    training_score_svm = svm.score(X_train, y_train) \n",
    "    testing_socre_svm = svm.score(X_test, y_test)\n",
    "    print(training_score_svm, testing_score_svm)\n",
    "    # 2. Tuning C and max_iter, compare the results\n",
    "    svm_linear_tuned = LinearSVC(C=0.1, max_iter = 100000)\n",
    "    svm_linear_tuned.fit(X_train, y_train)\n",
    "    training_score_svm = svm_linear_tuned.score(X_train, y_train) \n",
    "    testing_socre_svm = svm_linear_tuned.score(X_test, y_test)\n",
    "    print(training_score_svm, testing_socre_svm)\n",
    "    # TO DO：\n",
    "    # 1. Using kernel SVM (with Gaussian Kernel) (default setting), report the training and testing accuracy\n",
    "    svm_gauss = SVC(kernel = 'rbf')\n",
    "    svm_gauss.fit(X_train, y_train)\n",
    "    training_score_svmG = svm_gauss.score(X_train, y_train) \n",
    "    testing_score_svmG = svm_gauss.score(X_test, y_test)\n",
    "    print(training_score_svmG, testing_score_svmG)\n",
    "    # 2. Tuning C and max_iter, compare the results\n",
    "    svm_gaussian_tuned = SVC(kernel = 'rbf', C=100, max_iter = 10000)\n",
    "    svm_gaussian_tuned.fit(X_train, y_train)\n",
    "    training_score_svm = svm_gaussian_tuned.score(X_train, y_train) \n",
    "    testing_socre_svm = svm_gaussian_tuned.score(X_test, y_test)\n",
    "    print(training_score_svm, testing_socre_svm)\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "\t# API usage \n",
    "\tmain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e959ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f900b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e28d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b7526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d6d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
